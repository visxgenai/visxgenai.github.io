1:"$Sreact.fragment"
2:I[777,["177","static/chunks/app/layout-e75a3cd7028c5756.js"],"default"]
3:I[7555,[],""]
4:I[1295,[],""]
5:I[9665,[],"MetadataBoundary"]
7:I[9665,[],"OutletBoundary"]
a:I[4911,[],"AsyncMetadataOutlet"]
c:I[9665,[],"ViewportBoundary"]
e:I[6614,[],""]
:HL["/_next/static/media/a34f9d1faa5f3315-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/d8c58d50804a83f1.css","style"]
0:{"P":null,"b":"I22dp7rldAYODSAcOblnx","p":"","c":["","submit"],"i":false,"f":[[["",{"children":["submit",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d8c58d50804a83f1.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__className_d65c78","children":["$","div",null,{"className":"flex flex-col min-h-screen","children":[["$","$L2",null,{}],["$","main",null,{"className":"flex-grow container mx-auto px-4 py-2 mt-1","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"className":"bg-[#e0e8f5] border-t border-[#c1d1ea] py-4","children":["$","div",null,{"className":"container mx-auto px-4","children":["$","div",null,{"className":"flex justify-between items-center","children":[["$","div",null,{"className":"flex space-x-16","children":[["$","span",null,{"className":"text-gray-800 text-xl","children":"Logo1"}],["$","span",null,{"className":"text-gray-800 text-xl","children":"Logo2"}]]}],["$","div",null,{"className":"flex space-x-16","children":[["$","span",null,{"className":"text-gray-800 text-xl","children":"Logo3"}],["$","span",null,{"className":"text-gray-800 text-xl","children":"Logo4"}],["$","span",null,{"className":"text-gray-800 text-xl","children":"Logo5"}]]}]]}]}]}]]}]}]}]]}],{"children":["submit",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","div",null,{"className":"max-w-6xl mx-auto px-4 py-2 font-lato","children":[["$","h1",null,{"className":"text-4xl  text-gray-800 mb-6","children":"Submit Your Work"}],["$","section",null,{"className":"mb-8","children":[["$","h2",null,{"className":"text-2xl mb-4","children":"Submission Guidelines"}],["$","p",null,{"className":"mb-6","children":"We invite participation through two submission tracks: short paper and mini-challenge. Both are opportunities to showcase novel ideas and engage with the growing community at the intersection of visualization, generative AI, and agentic systems."}],["$","div",null,{"className":"mb-8","children":[["$","h3",null,{"className":"text-xl mb-3","children":"Paper Submission"}],["$","p",null,{"className":"mb-4","children":"We invite short papers (2–4 pages, non-archival). Submissions will be reviewed by at least two reviewers. Accepted papers will be invited to present as posters, demos, or lightning talks during the workshop, and published on the workshop website."}],["$","p",null,{"className":"mb-4","children":"We encourage diverse contributions across theory, systems, user studies, and applications, connecting VIS with GenAI or agentic workflows. Topics include (but are not limited to):"}],["$","div",null,{"className":"mb-6","children":[["$","h4",null,{"className":"text-lg font-semibold mb-2","children":"VIS X GenAI Interpretability"}],["$","ul",null,{"className":"list-disc pl-5 mb-4","children":[["$","li",null,{"className":"mb-3","children":["Novel visualization systems and techniques for interpreting frontier generative models, such as LLMs or diffusion models",["$","p",null,{"className":"text-sm text-gray-600 mt-1","children":"> Example papers"}]]}],["$","li",null,{"className":"mb-3","children":["Interpretability-focused papers from the GenAI community that highlight technical challenges or opportunities where visualization can help",["$","p",null,{"className":"text-sm text-gray-600 mt-1","children":"> Example papers"}]]}],["$","li",null,{"className":"mb-3","children":["Position papers and proposals outlining research agendas, benchmarks, or tools to support future collaboration between VIS and interpretability researchers",["$","p",null,{"className":"text-sm text-gray-600 mt-1","children":"> Example papers"}]]}]]}]]}],["$","div",null,{"className":"mb-6","children":[["$","h4",null,{"className":"text-lg font-semibold mb-2","children":"Agentic Systems and VIS"}],["$","ul",null,{"className":"list-disc pl-5 mb-4","children":[["$","li",null,{"className":"mb-3","children":"Agent-augmented VIS tools: agents that recommend, generate, or evaluate visualizations for human users"}],["$","li",null,{"className":"mb-3","children":"VIS tools for agents: encodings and UIs that agents themselves can perceive, reason over, or act upon"}],["$","li",null,{"className":"mb-3","children":"Benchmarks and evaluations for assessing agent performance on VIS-related tasks"}],["$","li",null,{"className":"mb-3","children":"Case studies and demos of agent systems applied to real-world visual analysis workflows"}],["$","li",null,{"className":"mb-3","children":"Vision papers on agents in VIS education, immersive visualizations for embodied agents, or multi-agent coordination in visual reasoning"}]]}]]}],["$","div",null,{"className":"mb-6","children":[["$","h4",null,{"className":"text-lg font-semibold mb-2","children":"Submission & Review"}],["$","p",null,{"children":"Submission will be made via PCS. Each paper will receive at least two reviews. Accepted papers will be presented and published on the workshop website."}]]}]]}],["$","div",null,{"className":"mb-8","children":[["$","h3",null,{"className":"text-xl font-semibold mb-3","children":"Mini-Challenge"}],["$","p",null,{"className":"mb-4","children":"Inspired by challenges like ImageNet in computer vision and HELM in language models, our mini-challenge invites participants to build or adapt AI agents that can automatically analyze datasets and generate visual data reports."}],["$","p",null,{"className":"mb-4","children":"The goal is to benchmark and accelerate progress in agent-based data analysis and communication. We will provide a starter kit and evaluation setup to support participants. More details—including datasets, templates, and submission instructions—will be released soon."}],["$","p",null,{"className":"font-semibold italic","children":"Stay tuned!"}]]}]]}],["$","section",null,{"className":"mb-8","children":[["$","h2",null,{"className":"text-2xl font-semibold mb-4","children":"Important Dates"}],["$","ul",null,{"className":"list-none pl-0 mb-4","children":[["$","li",null,{"className":"mb-2","children":"July 30, 2025, anywhere: Submission Deadline"}],["$","li",null,{"className":"mb-2","children":"September 1, 2025: Author Notification"}],["$","li",null,{"className":"mb-2","children":"October 1, 2025: Camera Ready Deadline"}]]}]]}],["$","div",null,{"className":"mt-6","children":["$","button",null,{"className":"bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600 transition-colors","children":"Go to template"}]}]]}],["$","$L5",null,{"children":"$L6"}],null,["$","$L7",null,{"children":["$L8","$L9",["$","$La",null,{"promise":"$@b"}]]}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","6dldWSkgTNdHfGBvFBIih",{"children":[["$","$Lc",null,{"children":"$Ld"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],null]}],false]],"m":"$undefined","G":["$e","$undefined"],"s":false,"S":true}
f:"$Sreact.suspense"
10:I[4911,[],"AsyncMetadata"]
6:["$","$f",null,{"fallback":null,"children":["$","$L10",null,{"promise":"$@11"}]}]
9:null
d:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
8:null
11:{"metadata":[["$","title","0",{"children":"VISxGenAI"}],["$","meta","1",{"name":"description","content":"Workshop on Explainable Visualizations focusing on AI techniques"}],["$","link","2",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}]],"error":null,"digest":"$undefined"}
b:{"metadata":"$11:metadata","error":null,"digest":"$undefined"}
