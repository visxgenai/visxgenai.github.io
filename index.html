<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/ac91f40814532a53.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-8f14a0b048916c48.js"/><script src="/_next/static/chunks/4bd1b696-52a6696c08e3276c.js" async=""></script><script src="/_next/static/chunks/684-75fd5dfdef93026f.js" async=""></script><script src="/_next/static/chunks/main-app-4782b4ea572e5255.js" async=""></script><script src="/_next/static/chunks/app/layout-987204e0fcbf31bf.js" async=""></script><script src="/_next/static/chunks/app/page-7fc2551a880c322f.js" async=""></script><meta name="next-size-adjust" content=""/><title>VISxGenAI</title><meta name="description" content="Workshop on Explainable Visualizations focusing on AI techniques"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_d65c78"><div class="flex flex-col min-h-screen bg-[#eff3f7]"><div class="fixed top-0 left-0 right-0 z-50 bg-white"><nav class="fixed top-0 w-full z-50 py-4 px-50 font-sans text-lg" style="transition:background-color 0.3s ease;background-color:rgba(255, 255, 255, 0)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between h-16"><div class="flex-shrink-0 flex items-center"><a class="text-[#333] text-xl md:text-2xl" href="/">VIS x GenAI</a></div><div class="hidden md:flex items-center space-x-4"><a class="px-3 py-2 rounded-md text-[#333] hover:bg-[#d0dbed] transition-colors text-lg" href="#cfp">Call for Papers</a><a class="px-3 py-2 rounded-md text-[#333] hover:bg-[#d0dbed] transition-colors text-lg" href="#important-dates">Important Dates</a><a class="px-3 py-2 rounded-md text-[#333] hover:bg-[#d0dbed] transition-colors text-lg" href="#vision">Vision</a><a class="px-3 py-2 rounded-md text-[#333] hover:bg-[#d0dbed] transition-colors text-lg" href="#pc">Program Committee</a><a class="px-3 py-2 rounded-md text-[#333] hover:bg-[#d0dbed] transition-colors text-lg" href="#schedule">Schedule</a></div><div class="md:hidden flex items-center"><button class="text-[#333] hover:bg-[#d0dbed] p-2 rounded-md focus:outline-none"><span class="sr-only">Open main menu</span><svg class="h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></div></nav></div><section id="home" class="mb-5"><div class="relative rounded-lg overflow-hidden h-[500px]"><div class="absolute inset-0 bg-cover bg-center" style="background-image:url(&#x27;/images/visxgenai.png&#x27;);background-blend-mode:overlay;background-color:rgb(255, 255, 255)"><div class="absolute inset-0 bg-black/2"></div></div><div class="relative z-10 flex flex-col justify-center items-center h-full p-6 text-black"><header class="flex justify-center items-center w-full mb-10"><h1 class="font-bold" style="font-size:clamp(1.25rem, 4vw, 3rem)">1<sup>st</sup> Workshop on<br/>GenAI, Agents and the Future of VIS</h1><div class="text-purple-300 ml-4"><svg width="60" height="60" viewBox="0 0 60 60" fill="none"><path d="M15 10L45 50" stroke="#FF6B6B" stroke-width="6" stroke-linecap="round"></path><path d="M45 10L15 50" stroke="#6B66FF" stroke-width="6" stroke-linecap="round"></path></svg></div></header><p class="text-xl text-center" style="font-size:clamp(0.5rem, 5vw, 1rem)">IEEE VIS&#x27;2025 | November, 2025 | Vienna, Austria</p></div></div></section><main class="flex-grow container mx-auto px-4 py-2 mt-1"><div class="max-w-4xl mx-auto px-4 py-2 font-lato"><section class="mb-8 section" id="about"><p class="text-gray-700 mb-4">The rapid evolution of generative AI and intelligent agents is transforming how we interact with, understand, and visualize data. As these technologies continue to advance, we stand at the frontier of new visualization paradigms that will shape the future of the VIS community.</p><p class="text-gray-700 mb-4">VISxGenAI brings together researchers, practitioners, and innovators exploring the intersection of generative AI, autonomous agents, and visualization. Our workshop aims to address critical questions: How can visualization techniques evolve to collaborate with AI systems? What novel interfaces will emerge in agent-augmented analytics? How might generative AI reshape visualization authoring and consumption?</p></section><section class="mb-8"><p class="text-gray-700 mb-4">Example interactive visualization articles that explain general concepts and communicate experimental insights when playing with AI models:</p><ul class="space-y-2"><li class="text-gray-700">(<!-- -->a<!-- -->)<!-- --> <a href="https://distill.pub/2019/visual-exploration-gaussian-processes/" class="text-green-600 hover:underline">A Visual Exploration of Gaussian Processes</a> <!-- -->by <!-- -->Görtler, Kehlbeck, and Deussen<span> (<!-- -->2018<!-- -->)</span></li><li class="text-gray-700">(<!-- -->b<!-- -->)<!-- --> <a href="#" class="text-green-600 hover:underline">What Makes Language Models Learned?</a> <!-- -->by <!-- -->Adam Pearce<span> (<!-- -->2021<!-- -->)</span></li><li class="text-gray-700">(<!-- -->c<!-- -->)<!-- --> <a href="#" class="text-green-600 hover:underline">What if we Reduce the Memory of an Artificial Doom Player?</a> <!-- -->by <!-- -->Jaunet, Vuillemot, and Wolf<span> (<!-- -->2019<!-- -->)</span></li><li class="text-gray-700">(<!-- -->d<!-- -->)<!-- --> <a href="#" class="text-green-600 hover:underline">K-Means Clustering: An Explorable Explainer</a> <!-- -->by <!-- -->Yi Zhe Ang<span> (<!-- -->2022<!-- -->)</span></li><li class="text-gray-700">(<!-- -->e<!-- -->)<!-- --> <a href="#" class="text-green-600 hover:underline">Comparing DNNs with UMAP Tour</a> <!-- -->by <!-- -->Li and Scheidegger<span> (<!-- -->2020<!-- -->)</span></li><li class="text-gray-700">(<!-- -->f<!-- -->)<!-- --> <a href="#" class="text-green-600 hover:underline">Can Large Language Models Explain Their Internal Mechanisms?</a> <!-- -->by <!-- -->Hussein, Ghandeharioun, Mullins, Reif, Wilson, Thain, Dixon<span> (<!-- -->2024<!-- -->)</span></li><li class="text-gray-700">(<!-- -->g<!-- -->)<!-- --> <a href="#" class="text-green-600 hover:underline">FormaFluens Data Experiment</a> <!-- -->by <!-- -->Strobelt, Phibbs, and Martino</li><li class="text-gray-700">(<!-- -->h<!-- -->)<!-- --> <a href="#" class="text-green-600 hover:underline">The Beginner&#x27;s Guide to Dimensionality Reduction</a> <!-- -->by <!-- -->Conlen and Hohman<span> (<!-- -->2018<!-- -->)</span></li></ul></section><section class="mb-8 section" id="important-dates"><h2 class="text-3xl font-bold text-gray-800 mb-4">Important Dates</h2><ul class="space-y-1"><li class="text-gray-700">May 30th, 2025: Call for Participation</li><li class="text-gray-700">Aug 20, 2025, anywhere: Submission Deadline</li><li class="text-gray-700">September 1, 2025: Author Notification</li><li class="text-gray-700">October 1, 2025: Camera Ready Deadline</li><li class="text-gray-700">Nov 2nd or 3rd: Workshop Day, TBD</li></ul></section><div class="mb-8 section" id="cfp"><h1 class="text-3xl font-bold text-gray-800 mb-4">Call for Participants</h1><p class="mb-5">We invite participation through two submission tracks: short paper and mini-challenge. Both are opportunities to showcase novel ideas and engage with the growing community at the intersection of visualization, generative AI, and agentic systems.</p><section class="mb-5"><div class="mb-5"><h2 class="text-2xl mb-4">Paper Submission</h2><p class="mb-4">We invite short papers (2–4 pages, non-archival). Submissions will be reviewed by at least two reviewers. Accepted papers will be invited to present as posters, demos, or lightning talks during the workshop, and published on the workshop website.</p><p class="mb-4">We encourage diverse contributions across theory, systems, user studies, and applications, connecting VIS with GenAI or agentic workflows. Topics include (but are not limited to):</p><div class="mb-5"><h4 class="font-semibold mb-2">VIS X GenAI Interpretability</h4><ul class="list-disc pl-5 mb-4"><li class="mb-3">Novel visualization systems and techniques for interpreting frontier generative models, such as LLMs or diffusion models<div class="mt-1"><button class="text-sm text-blue-600 hover:text-blue-800 flex items-center"><span>▶</span><span class="ml-1">Example papers</span></button></div></li><li class="mb-3">Interpretability-focused papers from the GenAI community that highlight technical challenges or opportunities where visualization can help<div class="mt-1"><button class="text-sm text-blue-600 hover:text-blue-800 flex items-center"><span>▶</span><span class="ml-1">Example papers</span></button></div></li><li class="mb-3">Position papers and proposals outlining research agendas, benchmarks, or tools to support future collaboration between VIS and interpretability researchers<div class="mt-1"><button class="text-sm text-blue-600 hover:text-blue-800 flex items-center"><span>▶</span><span class="ml-1">Example papers</span></button></div></li></ul></div><div class="mb-3"><h4 class="font-semibold mb-2">Agentic Systems and VIS</h4><ul class="list-disc pl-5 mb-3"><li class="mb-2">Agent-augmented VIS tools: agents that recommend, generate, or evaluate visualizations for human users</li><li class="mb-2">VIS tools for agents: encodings and UIs that agents themselves can perceive, reason over, or act upon</li><li class="mb-2">Benchmarks and evaluations for assessing agent performance on VIS-related tasks</li><li class="mb-2">Case studies and demos of agent systems applied to real-world visual analysis workflows</li><li class="mb-2">Vision papers on agents in VIS education, immersive visualizations for embodied agents, or multi-agent coordination in visual reasoning</li></ul></div></div><div class="mb-6"><h2 class="text-2xl mb-4">Mini-Challenge</h2><p class="mb-4">Inspired by challenges like ImageNet in computer vision and HELM in language models, our mini-challenge invites participants to build or adapt AI agents that can automatically analyze datasets and generate visual data reports.</p><p class="mb-4">The goal is to benchmark and accelerate progress in agent-based data analysis and communication. We will provide a starter kit and evaluation setup to support participants. More details—including datasets, templates, and submission instructions—will be released soon.</p><p class="font-semibold italic">Stay tuned!</p></div></section></div><section class="mb-8 section" id="pc"><h2 class="text-3xl font-bold text-gray-800 mb-4">Program Committee and Reviewers</h2><p class="text-gray-700">Coming soon!</p></section><section class="mb-8 section" id="schedule"><h2 class="text-3xl font-bold text-gray-800 mb-4">Schedule</h2><p class="text-gray-700">Workshop Schedule &amp; Program Overview Coming soon!</p></section><section class="mb-8 section" id="organizers"><h2 class="text-3xl font-bold text-gray-800 mb-4">Organizers</h2></section></div><!--$--><!--/$--><!--$--><!--/$--></main></div><script src="/_next/static/chunks/webpack-8f14a0b048916c48.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[8088,[\"177\",\"static/chunks/app/layout-987204e0fcbf31bf.js\"],\"default\"]\n3:I[7555,[],\"\"]\n4:I[1295,[],\"\"]\n5:I[8423,[\"974\",\"static/chunks/app/page-7fc2551a880c322f.js\"],\"default\"]\n6:I[9665,[],\"MetadataBoundary\"]\n8:I[9665,[],\"OutletBoundary\"]\nb:I[4911,[],\"AsyncMetadataOutlet\"]\nd:I[9665,[],\"ViewportBoundary\"]\nf:I[6614,[],\"\"]\n:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/ac91f40814532a53.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"j0O_I2rF2HDdUTLmSg3qo\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ac91f40814532a53.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_d65c78\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col min-h-screen bg-[#eff3f7]\",\"children\":[[\"$\",\"div\",null,{\"className\":\"fixed top-0 left-0 right-0 z-50 bg-white\",\"children\":[\"$\",\"$L2\",null,{}]}],[\"$\",\"section\",null,{\"id\":\"home\",\"className\":\"mb-5\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative rounded-lg overflow-hidden h-[500px]\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute inset-0 bg-cover bg-center\",\"style\":{\"backgroundImage\":\"url('/images/visxgenai.png')\",\"backgroundBlendMode\":\"overlay\",\"backgroundColor\":\"rgb(255, 255, 255)\"},\"children\":[\"$\",\"div\",null,{\"className\":\"absolute inset-0 bg-black/2\"}]}],[\"$\",\"div\",null,{\"className\":\"relative z-10 flex flex-col justify-center items-center h-full p-6 text-black\",\"children\":[[\"$\",\"header\",null,{\"className\":\"flex justify-center items-center w-full mb-10\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"font-bold\",\"style\":{\"fontSize\":\"clamp(1.25rem, 4vw, 3rem)\"},\"children\":[\"1\",[\"$\",\"sup\",null,{\"children\":\"st\"}],\" Workshop on\",[\"$\",\"br\",null,{}],\"GenAI, Agents and the Future of VIS\"]}],[\"$\",\"div\",null,{\"className\":\"text-purple-300 ml-4\",\"children\":[\"$\",\"svg\",null,{\"width\":\"60\",\"height\":\"60\",\"viewBox\":\"0 0 60 60\",\"fill\":\"none\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M15 10L45 50\",\"stroke\":\"#FF6B6B\",\"strokeWidth\":\"6\",\"strokeLinecap\":\"round\"}],[\"$\",\"path\",null,{\"d\":\"M45 10L15 50\",\"stroke\":\"#6B66FF\",\"strokeWidth\":\"6\",\"strokeLinecap\":\"round\"}]]}]}]]}],[\"$\",\"p\",null,{\"className\":\"text-xl text-center\",\"style\":{\"fontSize\":\"clamp(0.5rem, 5vw, 1rem)\"},\"children\":\"IEEE VIS'2025 | November, 2025 | Vienna, Austria\"}]]}]]}]}],[\"$\",\"main\",null,{\"className\":\"flex-grow container mx-auto px-4 py-2 mt-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 py-2 font-lato\",\"children\":[[\"$\",\"section\",null,{\"className\":\"mb-8 section\",\"id\":\"about\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-gray-700 mb-4\",\"children\":\"The rapid evolution of generative AI and intelligent agents is transforming how we interact with, understand, and visualize data. As these technologies continue to advance, we stand at the frontier of new visualization paradigms that will shape the future of the VIS community.\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 mb-4\",\"children\":\"VISxGenAI brings together researchers, practitioners, and innovators exploring the intersection of generative AI, autonomous agents, and visualization. Our workshop aims to address critical questions: How can visualization techniques evolve to collaborate with AI systems? What novel interfaces will emerge in agent-augmented analytics? How might generative AI reshape visualization authoring and consumption?\"}]]}],[\"$\",\"section\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-gray-700 mb-4\",\"children\":\"Example interactive visualization articles that explain general concepts and communicate experimental insights when playing with AI models:\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-2\",\"children\":[[\"$\",\"li\",\"a\",{\"className\":\"text-gray-700\",\"children\":[\"(\",\"a\",\")\",\" \",[\"$\",\"a\",null,{\"href\":\"https://distill.pub/2019/visual-exploration-gaussian-processes/\",\"className\":\"text-green-600 hover:underline\",\"children\":\"A Visual Exploration of Gaussian Processes\"}],\" \",\"by \",\"Görtler, Kehlbeck, and Deussen\",[\"$\",\"span\",null,{\"children\":[\" (\",\"2018\",\")\"]}]]}],[\"$\",\"li\",\"b\",{\"className\":\"text-gray-700\",\"children\":[\"(\",\"b\",\")\",\" \",[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"text-green-600 hover:underline\",\"children\":\"What Makes Language Models Learned?\"}],\" \",\"by \",\"Adam Pearce\",[\"$\",\"span\",null,{\"children\":[\" (\",\"2021\",\")\"]}]]}],[\"$\",\"li\",\"c\",{\"className\":\"text-gray-700\",\"children\":[\"(\",\"c\",\")\",\" \",[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"text-green-600 hover:underline\",\"children\":\"What if we Reduce the Memory of an Artificial Doom Player?\"}],\" \",\"by \",\"Jaunet, Vuillemot, and Wolf\",[\"$\",\"span\",null,{\"children\":[\" (\",\"2019\",\")\"]}]]}],[\"$\",\"li\",\"d\",{\"className\":\"text-gray-700\",\"children\":[\"(\",\"d\",\")\",\" \",[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"text-green-600 hover:underline\",\"children\":\"K-Means Clustering: An Explorable Explainer\"}],\" \",\"by \",\"Yi Zhe Ang\",[\"$\",\"span\",null,{\"children\":[\" (\",\"2022\",\")\"]}]]}],[\"$\",\"li\",\"e\",{\"className\":\"text-gray-700\",\"children\":[\"(\",\"e\",\")\",\" \",[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"text-green-600 hover:underline\",\"children\":\"Comparing DNNs with UMAP Tour\"}],\" \",\"by \",\"Li and Scheidegger\",[\"$\",\"span\",null,{\"children\":[\" (\",\"2020\",\")\"]}]]}],[\"$\",\"li\",\"f\",{\"className\":\"text-gray-700\",\"children\":[\"(\",\"f\",\")\",\" \",[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"text-green-600 hover:underline\",\"children\":\"Can Large Language Models Explain Their Internal Mechanisms?\"}],\" \",\"by \",\"Hussein, Ghandeharioun, Mullins, Reif, Wilson, Thain, Dixon\",[\"$\",\"span\",null,{\"children\":[\" (\",\"2024\",\")\"]}]]}],[\"$\",\"li\",\"g\",{\"className\":\"text-gray-700\",\"children\":[\"(\",\"g\",\")\",\" \",[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"text-green-600 hover:underline\",\"children\":\"FormaFluens Data Experiment\"}],\" \",\"by \",\"Strobelt, Phibbs, and Martino\",\"\"]}],[\"$\",\"li\",\"h\",{\"className\":\"text-gray-700\",\"children\":[\"(\",\"h\",\")\",\" \",[\"$\",\"a\",null,{\"href\":\"#\",\"className\":\"text-green-600 hover:underline\",\"children\":\"The Beginner's Guide to Dimensionality Reduction\"}],\" \",\"by \",\"Conlen and Hohman\",[\"$\",\"span\",null,{\"children\":[\" (\",\"2018\",\")\"]}]]}]]}]]}],[\"$\",\"section\",null,{\"className\":\"mb-8 section\",\"id\":\"important-dates\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 mb-4\",\"children\":\"Important Dates\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",null,{\"className\":\"text-gray-700\",\"children\":\"May 30th, 2025: Call for Participation\"}],[\"$\",\"li\",null,{\"className\":\"text-gray-700\",\"children\":\"Aug 20, 2025, anywhere: Submission Deadline\"}],[\"$\",\"li\",null,{\"className\":\"text-gray-700\",\"children\":\"September 1, 2025: Author Notification\"}],[\"$\",\"li\",null,{\"className\":\"text-gray-700\",\"children\":\"October 1, 2025: Camera Ready Deadline\"}],[\"$\",\"li\",null,{\"className\":\"text-gray-700\",\"children\":\"Nov 2nd or 3rd: Workshop Day, TBD\"}]]}]]}],[\"$\",\"$L5\",null,{}],[\"$\",\"section\",null,{\"className\":\"mb-8 section\",\"id\":\"pc\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 mb-4\",\"children\":\"Program Committee and Reviewers\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700\",\"children\":\"Coming soon!\"}]]}],[\"$\",\"section\",null,{\"className\":\"mb-8 section\",\"id\":\"schedule\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 mb-4\",\"children\":\"Schedule\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700\",\"children\":\"Workshop Schedule \u0026 Program Overview Coming soon!\"}]]}],[\"$\",\"section\",null,{\"className\":\"mb-8 section\",\"id\":\"organizers\",\"children\":[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold text-gray-800 mb-4\",\"children\":\"Organizers\"}]}]]}],[\"$\",\"$L6\",null,{\"children\":\"$L7\"}],null,[\"$\",\"$L8\",null,{\"children\":[\"$L9\",\"$La\",[\"$\",\"$Lb\",null,{\"promise\":\"$@c\"}]]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"FqW0rJoXd0UGqdQtxn6Ev\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:\"$Sreact.suspense\"\n11:I[4911,[],\"AsyncMetadata\"]\n7:[\"$\",\"$10\",null,{\"fallback\":null,\"children\":[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]}]\n"])</script><script>self.__next_f.push([1,"a:null\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n9:null\n"])</script><script>self.__next_f.push([1,"12:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"VISxGenAI\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Workshop on Explainable Visualizations focusing on AI techniques\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]],\"error\":null,\"digest\":\"$undefined\"}\nc:{\"metadata\":\"$12:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>